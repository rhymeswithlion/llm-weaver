{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Transitions Roberta Base SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"textattack/roberta-base-MNLI\"\n",
    "model_id = \"JeremiahZ/roberta-base-sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: visions 0.7.5 does not provide the extra 'type-image-path'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "\n",
    "! pip install -q joblib  # joblib for memoizing functions\n",
    "! pip install -q ipywidgets widgetsnbextension pandas-profiling # IProgress for progress bars\n",
    "\n",
    "# ! pip install -q tensorflow==2.13.0 tensorflow-datasets==4.9.2 tensorflow-probability==0.21.0 transformers==4.35.0  datasets==2.14.6 torch==2.1.0 scipy==1.10.1 scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model_merging to the python path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "model_merging_base = os.path.abspath(\"../model_merging/\")\n",
    "# assert it exist\n",
    "assert os.path.exists(model_merging_base)\n",
    "if model_merging_base not in sys.path:\n",
    "    sys.path.append(model_merging_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib for caching and distributed computing\n",
    "from math import sqrt\n",
    "\n",
    "from joblib import Memory, Parallel, delayed\n",
    "\n",
    "memory = Memory(location=\"cache\", verbose=10)\n",
    "\n",
    "parallel = Parallel(n_jobs=2, return_as=\"generator\")\n",
    "output_generator = parallel(delayed(sqrt)(i**2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and cached functions\n",
    "\n",
    "import os\n",
    "\n",
    "from llm_weaver import (\n",
    "    calculate_score_from_weaving_config,\n",
    "    test_weaver,\n",
    ")\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "calculate_score_from_weaving_config_cached = memory.cache(\n",
    "    calculate_score_from_weaving_config\n",
    ")\n",
    "test_weaver_cached = memory.cache(test_weaver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Test weaving code\n",
    "\n",
    "This test makes sure that our score when using the weaver to reconstruct a model from all its parts get the same evaluation score as the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps: configs to graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_weaver import dict_overwrite, get_model_config, normalize_glue_task_name\n",
    "\n",
    "\n",
    "def transitions_weave_configs_iter(model_id, trajectories=None, max_configs=None):\n",
    "    num_original_layers = get_model_config(model_id)[\"num_hidden_layers\"]\n",
    "\n",
    "    if trajectories is None:\n",
    "        x_y_layer_sequences = [\n",
    "            (x, y, (list(range(0, x + 1)) + list(range(y, num_original_layers))))\n",
    "            for x in range(num_original_layers)\n",
    "            for y in range(num_original_layers)\n",
    "        ]\n",
    "    else:\n",
    "        x_y_layer_sequences = [(None, None, trajectory) for trajectory in trajectories]\n",
    "\n",
    "    if max_configs is not None:\n",
    "        x_y_layer_sequences = x_y_layer_sequences[:max_configs]\n",
    "    for x, y, layer_sequence in x_y_layer_sequences:\n",
    "        layer_assignments = [\n",
    "            {\n",
    "                \"type\": \"SingleLayer\",\n",
    "                \"params\": {\n",
    "                    \"donor\": model_id,\n",
    "                    \"hidden_layer_number\": i,\n",
    "                },\n",
    "            }\n",
    "            for i in layer_sequence\n",
    "        ]\n",
    "\n",
    "        blank_model_config = dict_overwrite(\n",
    "            get_model_config(model_id),\n",
    "            {\n",
    "                \"num_hidden_layers\": len(layer_assignments),\n",
    "            },\n",
    "        )\n",
    "        config = {\n",
    "            \"glue_task\": normalize_glue_task_name(model_id),\n",
    "            \"tokenizer_model_id\": model_id,\n",
    "            \"blank_model_config\": blank_model_config,\n",
    "            \"layer_assignments\": layer_assignments,\n",
    "            \"classification_head\": {\n",
    "                \"type\": \"SingleClassificationHead\",\n",
    "                \"params\": {\n",
    "                    \"donor\": model_id,\n",
    "                },\n",
    "            },\n",
    "            \"embeddings\": {\n",
    "                \"type\": \"SingleEmbeddings\",\n",
    "                \"params\": {\n",
    "                    \"donor\": model_id,\n",
    "                },\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        yield config\n",
    "\n",
    "\n",
    "weave_configs = list(\n",
    "    transitions_weave_configs_iter(\n",
    "        model_id=model_id,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "len(weave_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9d9469d5257bd701db2c01cdeb4f5ad9\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cbe0bf38dcea304e19b02840ca5bbd7b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 79289781bb3a84ceaeff4c2778aab776\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: da3153d02633dd5e08039905a7ffa15b\n",
      "calculating score for weaving config md5sum: db9bbe8cd130877ff70481686a3936d7\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:39:55.868333: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:39:58.079037: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:39:58.974101: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:39:59.731377: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:00.936022: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 22.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: eab93f672c34c477a3ae5fcb5667fb40\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 25.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c7d0dea136dd9adca05bade62c2b2fc9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 27.2s, 0.5min\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d7a60079091362457fab0d8b441cdff4\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 28.8s, 0.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b99b934328385e23ac48fe41e86f6c19\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.3s, 0.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f419563bab6dc66d249131116729abbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:40:14.148611: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:40:17.321277: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:40:18.317001: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:18.359402: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:18.364925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 16.6s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d4229d9294f836f02059b336d42463a1\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 10.2s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b36e50f2bff433f2518ec89ca0db4ce9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 12.6s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4323193a17d16e1bc7b59c31c7ba86d6\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 15.8s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 601fb015c7b3482643ca416e7cdbee93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 14.9s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: fd5ed2eff86e9c2293d739bd469b33b7\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:40:25.004727: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:40:26.352031: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 5.9s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 141f4eed11939359c5fe2cfc29ca3d90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 5.4s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 0fadb3b9f694cefeea550d8bef920455\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:40:37.429628: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:39.364050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:40.226084: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:41.116853: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:40:41.756165: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 23.9s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 2786a57067020329570522923d731646\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 28.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 0a9bc1fbaca90f9bc3ea48e0433cd88e\n",
      "_____________________________calculate_score_from_weaving_config - 24.8s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 23.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c6be392bc72039a81713ba1ac7af7e54\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: e65669197112684a72a8ea1da0016dd7\n",
      "_____________________________calculate_score_from_weaving_config - 29.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: a121fd9d16c765e0d44c9747b1556e9a\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:40:57.774896: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:00.390210: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:00.837293: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:01.619158: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:02.907467: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 12.6s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1a36e454a0d21c404b896935db4f86cd\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 18.1s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f936cf7353a5e4b8fdcae9a61fe4d5e0\n",
      "_____________________________calculate_score_from_weaving_config - 15.2s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 918fb23d02cc0959db2d505bb0fbcbcc\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 16.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c589b4653b129cdfdadfee9da7fec613\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 18.6s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 262283c2aaee773d9710d2b6a7274a5e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:41:10.145491: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:41:11.476634: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 6.1s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 640bb76bd0c8222bf81e1f89d25980e2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "______________________________calculate_score_from_weaving_config - 9.9s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1cd85380fef138412442676a529246e5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:41:24.190683: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:25.976413: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:26.216436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:28.490145: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:30.278359: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 31.7s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 28.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: dcc5a47fa19cd6c6aa8db5970f3d7fd1\n",
      "_____________________________calculate_score_from_weaving_config - 31.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 517eea7c3b86ada6c1265b08703cd29c\n",
      "_____________________________calculate_score_from_weaving_config - 28.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: faab653f32152ffcf4220827eb9c8348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 25.8s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9f6c56f95eeb20b0698ab5c5fbc2727d\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b6dee44f7ddc6c41f60e26fda8c64f53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:41:47.748349: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:41:49.728769: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:49.808969: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:41:50.377112: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 12.6s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4813735a52ec634f9c55d381e602adf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 16.8s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 89f60805958c94c2e37cc14bedc12d95\n",
      "_____________________________calculate_score_from_weaving_config - 18.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1d0d28302686dcd281ef446926d56c29\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.2s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9a98dde203090b1bba4bb5600d32fb3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:41:58.779736: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:42:00.959652: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 15.0s, 0.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:42:02.640404: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 93d0fc088863febbb22c018cd5785f80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 11.4s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 73d4f9c6f692151c73fc75ce1e035a19\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 9.3s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1b185b055bd402c1674dcf46b72250f3\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:42:15.077581: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:17.077031: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:22.105852: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:22.136201: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:22.718202: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.6s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9f38fe17b8799c1c4c7bc2d2f42d2690\n",
      "_____________________________calculate_score_from_weaving_config - 31.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 2895eb26083c7cc4db434229fae50e8a\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 27.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cd7f95c7adf36c6f0ff556bc2e0d0351\n",
      "_____________________________calculate_score_from_weaving_config - 29.4s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 81c6eb743ce61e9f7f322e8a2ce28a67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 31.4s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 3d2d637d694c85591d46bec900c0fc26\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:42:42.512719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:43.756606: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:44.737854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:44.745656: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:42:46.050161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 16.7s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f63c212195da05a676dcbfa5fa11b9aa\n",
      "_____________________________calculate_score_from_weaving_config - 21.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1deba445aeb664d237b6c171dc179415\n",
      "_____________________________calculate_score_from_weaving_config - 18.1s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: bc76d9aeb5f75e021599fd6f2c1697af\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 23.2s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 05e15f03f9c072905e4423a8d87c9c44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 747ac574c16608b4518dd365af6c3f13\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:42:57.158697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:42:58.926865: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 9.8s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d7a32c09a4d5db558504f3a80dadd282\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 13.4s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 5078a0552af6d8d2b7a1ccc6bbabffd0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:43:10.733722: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:11.787916: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:12.408980: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:20.701303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:22.153842: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 31.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 3fc2730dd2715d07ad3d5a249f87c679\n",
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 34.7s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9d3b361e8f627ad0e0b12e90c54edf4b\n",
      "_____________________________calculate_score_from_weaving_config - 34.2s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: eabef50c82d18425c5f37ee740742a48\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 30.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 8920d92841d5a1de4155d1c64bfa5196\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 3a65531e393007e942e81edd80f9febf\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:43:40.075271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:41.549021: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:41.981757: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:44.477325: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:43:45.294709: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 21.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 6bc4bb6be89acb3e80228ef44c0c178e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 26.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: e1f6f1fa2b06e9c7e667386f04da31b8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 25.6s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 19.6s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 579fcc0a930b101f4b3a55bbecfb5491\n",
      "calculating score for weaving config md5sum: 8016ba172d33b5f96743bde398add6fa\n",
      "_____________________________calculate_score_from_weaving_config - 21.2s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 2b93c140c26568b55caf1cd0f71a68d5\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:43:56.794370: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:43:59.396402: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 13.9s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 239874e425927890a67c0e58f001a879\n",
      "_____________________________calculate_score_from_weaving_config - 12.9s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 7d1e6af07b86e9e8f43c4284546e7f3d\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:44:11.610115: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:12.830696: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:14.380376: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:23.226284: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:24.402296: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 34.9s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f4c26757719dc22f4e41d299ba9574a4\n",
      "_____________________________calculate_score_from_weaving_config - 34.7s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 64487a8f88a1c4b070fcd7d9b787a75c\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 38.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c29d0cf0c0f5e59664959f0c4654ef9a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 49c65140a9a92afb09340665a01859e0\n",
      "_____________________________calculate_score_from_weaving_config - 31.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: bc8942262c31c4aa2b9fd2d2c15e35f9\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:44:42.143375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:44.038526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:44.877775: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:48.730825: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:44:49.206147: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 25.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 7b6a8d76b5f6683a56153a32e8ac020d\n",
      "_____________________________calculate_score_from_weaving_config - 24.0s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4cab8227ccd3bfe5e61d224729ddd5b8\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 28.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 5fc5007968aed2a203e8aa7e6a65b070\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 22e84703cf8ddd2cc3dab6e41f8c87e7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 22.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c003fd512e42681def25f233fcf1ba8f\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:45:01.750783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:45:02.852317: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 13.3s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 0ec504a629e7853fff8b3ebbc990bd1d\n",
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 17.4s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9ccc772bab183b60d417f67bafc7b37f\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:45:16.395786: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:17.860573: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:18.360135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:29.802836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:30.762094: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 37.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4d72e11a6d61e6770b0bd2d30c0db689\n",
      "_____________________________calculate_score_from_weaving_config - 36.8s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 192ef55e89f42d875e3239d23d49eeff\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 40.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cdb2148ed6d815c0c51076606e9bdd4e\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 34.4s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 44112d2d6c3130e1ec75e4784c352b89\n",
      "_____________________________calculate_score_from_weaving_config - 32.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 958826ef74d814f687a7a8a494ee415e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:45:49.617290: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:50.900493: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:51.560272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:56.606960: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:45:57.528166: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 27.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9ede33a7ee47a9fb03be7025bf9830ee\n",
      "_____________________________calculate_score_from_weaving_config - 26.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4eb357b4ab4f0ad5390458cb6769a398\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 8d29ac570ed8ce0db0ce20b4b8c9fd85\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 22.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 971d7ae353e131ed6a1630ad75e146c2\n",
      "_____________________________calculate_score_from_weaving_config - 23.9s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 616253c41120856b3fadf8ce2570706c\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:46:10.510403: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:46:12.538000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 15.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: afb1d73cbece0ff0757651cab9f8e60b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 19.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 644acdc2db9eaaf73f76032732bc49fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:46:26.232653: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:46:27.815810: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:46:27.827102: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:46:39.485898: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:46:42.159394: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 40.3s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b95796ecfc8de449be68209f5242ae77\n",
      "_____________________________calculate_score_from_weaving_config - 38.9s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 7ab1449b2cf33f6a8fe93dbdb4d9c27f\n",
      "_____________________________calculate_score_from_weaving_config - 40.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: aed22f6a35f28f2289f0d25c283cbc66\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 35.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b885ea234fd934ee9c8aa62189adf687\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 34.4s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 93943aac752310de20535c91e78a56f6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:47:00.636243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:02.698410: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:02.708018: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:08.674032: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:10.849975: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 26.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 505b4245dc67bdf522b32cce7e2d383b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 005c3a0fee962539766547aa218d0cd4\n",
      "_____________________________calculate_score_from_weaving_config - 32.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 68ec58e3909f9a3a5f9f90c9ded9927c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 26.0s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 7658138ba96ca9557a8a461bf45db6f4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cd8a8e28eff8924f171dd566daae701f\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:47:23.382014: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:47:26.731137: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 19.7s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 295ac47f0c416531b506951573422d41\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 19.2s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: fcdaa19492b0a301e09082c07a4c1ac5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:47:40.387489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:42.526909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:42.615648: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:55.186958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:47:57.967558: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 43.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 3e8bd8ca763e918865e4446ea957b860\n",
      "_____________________________calculate_score_from_weaving_config - 40.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 62eba68e15add4aa1c409fbd71d8ca7e\n",
      "_____________________________calculate_score_from_weaving_config - 41.9s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 5b585b747144af160ea91c8fa7b50b3b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 37.5s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: de949aaa2d3631b96c7b672cdde20535\n",
      "_____________________________calculate_score_from_weaving_config - 36.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b93c0dfe68a4696cad5fd36624e7ceec\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:48:17.673631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:48:19.491049: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:48:19.552438: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:48:26.613080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:48:28.066218: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 29.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: ec27a302199a9dbfebe40f9df79373ec\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 32.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 646140e5cb913f8f96c12e0df20ee282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 34.4s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 690fd244417d151f876f0acd78270192\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 28.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4972d6fd00121d6168c1092ec1815dae\n",
      "_____________________________calculate_score_from_weaving_config - 26.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cf4afb69b803dc024b8859c5a313f638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:48:42.362785: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:48:44.697738: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 22.0s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: a8631210308d94d7ab1069afbe483368\n",
      "_____________________________calculate_score_from_weaving_config - 20.8s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 23901593ac10f1fda1fe40b624ffea82\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:48:58.067928: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:49:02.057287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:49:02.987753: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 43.9s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 6efbc7ce28357610a878a9e35efb5dc8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:49:17.737815: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:49:18.292373: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 41.7s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 9cf4956b5321a3babd6e9ab2b7cd2efc\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 44.5s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: fa29434ea2b5f4401a9fd75833db1b32\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 38.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 679132cae57fd8b093e689573bf002a8\n",
      "_____________________________calculate_score_from_weaving_config - 42.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 0b4a71d8f53600093a30b969a2256f00\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:49:38.116176: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:49:39.952013: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:49:40.810978: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:49:51.467122: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:49:51.704604: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 35.0s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: a399170c05290d164b1c74ab0f7321f2\n",
      "_____________________________calculate_score_from_weaving_config - 32.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 97a02d4846278ab4df669b2c56531077\n",
      "_____________________________calculate_score_from_weaving_config - 35.0s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d6ecea1604dc905aed59b1120602d7c2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 27.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b0d911a4a6f2b1f7cc05f28f86efc68f\n",
      "_____________________________calculate_score_from_weaving_config - 30.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 34a24a9779064e241c58c4b8b4a11d3b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:50:06.677136: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:50:08.429826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 8c3adbc20dbe4ee81f08ba27de82bbd2\n",
      "_____________________________calculate_score_from_weaving_config - 23.8s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 99dfec43e7f17791e6f2df76a7a70e68\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:50:21.231001: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:50:28.354853: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:50:28.546890: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 47.7s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 4dcc75170897119013feeb64f3fbd27d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:50:43.828107: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:50:46.121243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 46.4s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 07abd2242045258c8a9a955d0e85bae3\n",
      "_____________________________calculate_score_from_weaving_config - 48.7s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d8999a07f2d568f0793dd15ba9003104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 43.7s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 11c67c4253abb33673b5ecf48e48b4e5\n",
      "_____________________________calculate_score_from_weaving_config - 44.3s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 044a95b1c76b055d10a186e8ffc2cf5d\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:51:06.493819: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:51:10.776482: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:51:11.453639: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:51:22.076591: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:51:22.277107: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 40.2s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 75066cc5d1849da505321e134cf9b284\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 35.9s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: c94f7db8a0badb1dce8abcb1c0b52081\n",
      "_____________________________calculate_score_from_weaving_config - 37.6s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f4e19ecc655f7bc6f921e79982452956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 30.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 993e1f118a52d8b45753e8061c45f2b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 33.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 1bf6f61e24ba8c291c5c1d187a55ad4c\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:51:38.067244: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:51:41.168475: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 26.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 8db9721fffe2f71d02817939ad7a1046\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 26.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: aeee6e47145cc93ffb0adc22cef69def\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:51:54.654346: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:52:02.323030: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:52:02.348646: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 49.8s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: f1b8b9133d8432e5f4ebf700e917c6e9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:52:16.291121: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:52:20.569668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 48.8s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 6ce4af47a8114b0a9963b2503e66354d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 50.5s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 65f370eb356e4d9633f91aa87dfd78eb\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 44.3s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: cb59e9e261da88f26cda680532af5a38\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 44.9s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: b6ebd1453d7285b128443fcc46cb23da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:52:39.848085: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 13:52:45.735535: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:52:45.915074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:52:55.423080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 40.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: d2ba75193b00a9e6b1bcd73da77efef6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:52:57.726499: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 38.4s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='train')\n",
      "calculating score for weaving config md5sum: 079ed7b0e553f43a2805823ceb0878b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 40.1s, 0.7min\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 35.4s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 31.9s, 0.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:53:11.351687: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 13:53:14.529074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.6s, 0.3min\n",
      "_____________________________calculate_score_from_weaving_config - 17.3s, 0.3min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = Parallel(n_jobs=5, return_as=\"list\")(\n",
    "    delayed(calculate_score_from_weaving_config_cached)(\n",
    "        weave_config,\n",
    "        # n_examples=4096,\n",
    "        n_examples=128,\n",
    "        split=\"train\",\n",
    "    )\n",
    "    for weave_config in weave_configs\n",
    ")\n",
    "accuracies = [score[\"accuracy\"] for score in scores]\n",
    "\n",
    "\n",
    "records = []\n",
    "for weave_config, accuracy in zip(weave_configs, accuracies):\n",
    "    record = weave_config[\"metadata\"]\n",
    "    record[\"accuracy\"] = accuracy\n",
    "    records.append(record)\n",
    "df_big_grid_train = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x   y  accuracy\n",
       "0     0   0  0.492188\n",
       "1     0   1  0.750000\n",
       "2     0   2  0.750000\n",
       "3     0   3  0.671875\n",
       "4     0   4  0.578125\n",
       "..   ..  ..       ...\n",
       "139  11   7  0.679688\n",
       "140  11   8  0.703125\n",
       "141  11   9  0.664062\n",
       "142  11  10  0.726562\n",
       "143  11  11  0.726562\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_grid_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='y', ylabel='x'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a heatmap of the accuracy with respect to the layer transitions\n",
    "# x and y are the layer numbers of the first and last layer of the transition\n",
    "# the color is the accuracy\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(\n",
    "    df_big_grid_train.pivot(index=\"x\", columns=\"y\", values=\"accuracy\"),\n",
    "    annot=True,\n",
    "    # fmt=\".0%\",\n",
    "    # do not show numbers in the heatmap\n",
    "    # fmt=\".0f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar_kws={\"label\": \"Accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 79289781bb3a84ceaeff4c2778aab776\n",
      "calculating score for weaving config md5sum: cbe0bf38dcea304e19b02840ca5bbd7b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9d9469d5257bd701db2c01cdeb4f5ad9\n",
      "calculating score for weaving config md5sum: da3153d02633dd5e08039905a7ffa15b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: db9bbe8cd130877ff70481686a3936d7\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "2023-11-28 10:34:22.642357: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:24.664167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:25.731008: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:26.517255: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:27.271200: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 22.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: eab93f672c34c477a3ae5fcb5667fb40\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 25.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c7d0dea136dd9adca05bade62c2b2fc9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 27.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d7a60079091362457fab0d8b441cdff4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 28.9s, 0.5min\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b99b934328385e23ac48fe41e86f6c19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.4s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f419563bab6dc66d249131116729abbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:34:40.798053: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:34:43.546648: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:34:44.452855: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:44.774426: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:34:45.185052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 16.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d4229d9294f836f02059b336d42463a1\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 10.1s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b36e50f2bff433f2518ec89ca0db4ce9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 15.9s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4323193a17d16e1bc7b59c31c7ba86d6\n",
      "_____________________________calculate_score_from_weaving_config - 12.2s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 601fb015c7b3482643ca416e7cdbee93\n",
      "_____________________________calculate_score_from_weaving_config - 13.7s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: fd5ed2eff86e9c2293d739bd469b33b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2Loading JeremiahZ/roberta-base-sst2\n",
      "\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:34:51.489457: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 5.5s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 141f4eed11939359c5fe2cfc29ca3d90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:34:52.692082: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 5.3s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0fadb3b9f694cefeea550d8bef920455\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:35:03.736569: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:05.093514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:06.486802: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:07.729526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:07.859671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 2786a57067020329570522923d731646\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 23.0s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0a9bc1fbaca90f9bc3ea48e0433cd88e\n",
      "_____________________________calculate_score_from_weaving_config - 27.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c6be392bc72039a81713ba1ac7af7e54\n",
      "_____________________________calculate_score_from_weaving_config - 24.8s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: e65669197112684a72a8ea1da0016dd7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 29.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: a121fd9d16c765e0d44c9747b1556e9a\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:35:24.884732: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:26.064689: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:26.546333: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:27.008264: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:27.754611: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 11.8s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1a36e454a0d21c404b896935db4f86cd\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 14.1s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f936cf7353a5e4b8fdcae9a61fe4d5e0\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 18.4s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 918fb23d02cc0959db2d505bb0fbcbcc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 16.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c589b4653b129cdfdadfee9da7fec613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 17.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 262283c2aaee773d9710d2b6a7274a5e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:35:35.697052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:35:37.276167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________calculate_score_from_weaving_config - 7.3s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 640bb76bd0c8222bf81e1f89d25980e2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 8.0s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1cd85380fef138412442676a529246e5\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:35:49.400672: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:50.659600: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:50.878089: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:54.035671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:35:55.062351: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 27.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: dcc5a47fa19cd6c6aa8db5970f3d7fd1\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 517eea7c3b86ada6c1265b08703cd29c\n",
      "_____________________________calculate_score_from_weaving_config - 32.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: faab653f32152ffcf4220827eb9c8348\n",
      "_____________________________calculate_score_from_weaving_config - 27.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9f6c56f95eeb20b0698ab5c5fbc2727d\n",
      "_____________________________calculate_score_from_weaving_config - 25.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b6dee44f7ddc6c41f60e26fda8c64f53\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:36:12.726382: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:14.352076: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:14.712907: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:15.157998: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:15.281112: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 12.5s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4813735a52ec634f9c55d381e602adf4\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 16.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 89f60805958c94c2e37cc14bedc12d95\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 18.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1d0d28302686dcd281ef446926d56c29\n",
      "_____________________________calculate_score_from_weaving_config - 21.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9a98dde203090b1bba4bb5600d32fb3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 93d0fc088863febbb22c018cd5785f80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:36:25.154990: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:36:27.594424: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 10.3s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 73d4f9c6f692151c73fc75ce1e035a19\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "______________________________calculate_score_from_weaving_config - 9.6s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1b185b055bd402c1674dcf46b72250f3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:36:40.807053: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:42.051402: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:43.021675: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:45.285410: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:36:46.908854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 29.6s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9f38fe17b8799c1c4c7bc2d2f42d2690\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 32.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 2895eb26083c7cc4db434229fae50e8a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 29.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: cd7f95c7adf36c6f0ff556bc2e0d0351\n",
      "_____________________________calculate_score_from_weaving_config - 34.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 81c6eb743ce61e9f7f322e8a2ce28a67\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 27.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 3d2d637d694c85591d46bec900c0fc26\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:37:05.602575: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:07.647507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:08.521827: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:08.968445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:09.371717: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 15.9s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f63c212195da05a676dcbfa5fa11b9aa\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 21.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1deba445aeb664d237b6c171dc179415\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 18.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: bc76d9aeb5f75e021599fd6f2c1697af\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 19.9s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 05e15f03f9c072905e4423a8d87c9c44\n",
      "_____________________________calculate_score_from_weaving_config - 21.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 747ac574c16608b4518dd365af6c3f13\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:37:20.669287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:37:22.434147: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 10.0s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d7a32c09a4d5db558504f3a80dadd282\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 14.2s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5078a0552af6d8d2b7a1ccc6bbabffd0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:37:34.571813: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:35.730446: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:36.469738: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:43.806973: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:37:45.209166: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 3fc2730dd2715d07ad3d5a249f87c679\n",
      "_____________________________calculate_score_from_weaving_config - 34.0s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9d3b361e8f627ad0e0b12e90c54edf4b\n",
      "_____________________________calculate_score_from_weaving_config - 34.0s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: eabef50c82d18425c5f37ee740742a48\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 29.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8920d92841d5a1de4155d1c64bfa5196\n",
      "_____________________________calculate_score_from_weaving_config - 27.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 3a65531e393007e942e81edd80f9febf\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:38:02.988355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:04.368596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:05.358394: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:07.043522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:08.285196: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.8s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 6bc4bb6be89acb3e80228ef44c0c178e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 24.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: e1f6f1fa2b06e9c7e667386f04da31b8\n",
      "_____________________________calculate_score_from_weaving_config - 19.3s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 579fcc0a930b101f4b3a55bbecfb5491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 26.2s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8016ba172d33b5f96743bde398add6fa\n",
      "_____________________________calculate_score_from_weaving_config - 21.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 2b93c140c26568b55caf1cd0f71a68d5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:38:19.708938: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:38:21.506791: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 13.8s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 239874e425927890a67c0e58f001a879\n",
      "_____________________________calculate_score_from_weaving_config - 13.1s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7d1e6af07b86e9e8f43c4284546e7f3d\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:38:34.139403: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:35.280763: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:36.859867: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:46.239435: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:38:46.835738: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f4c26757719dc22f4e41d299ba9574a4\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 36.9s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 64487a8f88a1c4b070fcd7d9b787a75c\n",
      "_____________________________calculate_score_from_weaving_config - 36.2s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c29d0cf0c0f5e59664959f0c4654ef9a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 49c65140a9a92afb09340665a01859e0\n",
      "_____________________________calculate_score_from_weaving_config - 31.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: bc8942262c31c4aa2b9fd2d2c15e35f9\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:39:04.116182: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:05.697285: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:07.072583: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:11.302008: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:12.651681: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 23.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7b6a8d76b5f6683a56153a32e8ac020d\n",
      "_____________________________calculate_score_from_weaving_config - 27.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4cab8227ccd3bfe5e61d224729ddd5b8\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 26.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5fc5007968aed2a203e8aa7e6a65b070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.4s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 22e84703cf8ddd2cc3dab6e41f8c87e7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 22.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c003fd512e42681def25f233fcf1ba8f\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:39:23.928426: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:39:25.361024: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 13.7s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0ec504a629e7853fff8b3ebbc990bd1d\n",
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 17.2s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9ccc772bab183b60d417f67bafc7b37f\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:39:39.599931: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:40.721985: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:41.520723: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:51.551778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:39:53.421592: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 36.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4d72e11a6d61e6770b0bd2d30c0db689\n",
      "_____________________________calculate_score_from_weaving_config - 38.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 192ef55e89f42d875e3239d23d49eeff\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.8s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: cdb2148ed6d815c0c51076606e9bdd4e\n",
      "_____________________________calculate_score_from_weaving_config - 31.5s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 44112d2d6c3130e1ec75e4784c352b89\n",
      "_____________________________calculate_score_from_weaving_config - 46.7s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 958826ef74d814f687a7a8a494ee415e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:40:10.148844: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:12.272855: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:18.484481: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:18.909352: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:18.998648: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9ede33a7ee47a9fb03be7025bf9830ee\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 27.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4eb357b4ab4f0ad5390458cb6769a398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 22.6s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8d29ac570ed8ce0db0ce20b4b8c9fd85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.3s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 971d7ae353e131ed6a1630ad75e146c2\n",
      "_____________________________calculate_score_from_weaving_config - 25.8s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 616253c41120856b3fadf8ce2570706c\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:40:32.122963: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:40:34.236921: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 17.6s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: afb1d73cbece0ff0757651cab9f8e60b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 17.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 644acdc2db9eaaf73f76032732bc49fd\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:40:49.394418: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:50.599925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:40:51.455744: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:01.241801: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:03.157191: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 39.0s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b95796ecfc8de449be68209f5242ae77\n",
      "_____________________________calculate_score_from_weaving_config - 40.7s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7ab1449b2cf33f6a8fe93dbdb4d9c27f\n",
      "_____________________________calculate_score_from_weaving_config - 40.3s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: aed22f6a35f28f2289f0d25c283cbc66\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 35.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b885ea234fd934ee9c8aa62189adf687\n",
      "_____________________________calculate_score_from_weaving_config - 33.8s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 93943aac752310de20535c91e78a56f6\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:41:24.152247: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:25.427746: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:26.839507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:30.680838: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:31.616944: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 26.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 505b4245dc67bdf522b32cce7e2d383b\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 005c3a0fee962539766547aa218d0cd4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 32.2s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 68ec58e3909f9a3a5f9f90c9ded9927c\n",
      "_____________________________calculate_score_from_weaving_config - 26.4s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7658138ba96ca9557a8a461bf45db6f4\n",
      "_____________________________calculate_score_from_weaving_config - 25.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: cd8a8e28eff8924f171dd566daae701f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:41:46.056118: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:41:48.794358: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 20.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 295ac47f0c416531b506951573422d41\n",
      "_____________________________calculate_score_from_weaving_config - 19.4s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: fcdaa19492b0a301e09082c07a4c1ac5\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:42:02.892979: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:03.957198: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:04.536074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:19.320140: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:19.612417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 39.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 3e8bd8ca763e918865e4446ea957b860\n",
      "_____________________________calculate_score_from_weaving_config - 40.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 62eba68e15add4aa1c409fbd71d8ca7e\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 43.7s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5b585b747144af160ea91c8fa7b50b3b\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 35.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: de949aaa2d3631b96c7b672cdde20535\n",
      "_____________________________calculate_score_from_weaving_config - 38.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b93c0dfe68a4696cad5fd36624e7ceec\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:42:39.165563: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:41.213802: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:41.214540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:50.034854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:42:50.444769: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.9s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: ec27a302199a9dbfebe40f9df79373ec\n",
      "_____________________________calculate_score_from_weaving_config - 30.7s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 646140e5cb913f8f96c12e0df20ee282\n",
      "_____________________________calculate_score_from_weaving_config - 33.2s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 690fd244417d151f876f0acd78270192\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 25.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4972d6fd00121d6168c1092ec1815dae\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: cf4afb69b803dc024b8859c5a313f638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:43:05.068658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:43:06.096570: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 19.5s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: a8631210308d94d7ab1069afbe483368\n",
      "_____________________________calculate_score_from_weaving_config - 23.7s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 23901593ac10f1fda1fe40b624ffea82\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:43:19.472207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:43:24.120677: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:43:24.888902: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:43:38.222991: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 44.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 6efbc7ce28357610a878a9e35efb5dc8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:43:39.313676: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 44.0s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9cf4956b5321a3babd6e9ab2b7cd2efc\n",
      "_____________________________calculate_score_from_weaving_config - 42.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: fa29434ea2b5f4401a9fd75833db1b32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 39.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 679132cae57fd8b093e689573bf002a8\n",
      "_____________________________calculate_score_from_weaving_config - 37.7s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0b4a71d8f53600093a30b969a2256f00\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:43:58.581928: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:44:02.321570: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:44:03.107555: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:44:11.958199: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:44:12.109813: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 34.2s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: a399170c05290d164b1c74ab0f7321f2\n",
      "_____________________________calculate_score_from_weaving_config - 32.6s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 97a02d4846278ab4df669b2c56531077\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 34.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d6ecea1604dc905aed59b1120602d7c2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b0d911a4a6f2b1f7cc05f28f86efc68f\n",
      "_____________________________calculate_score_from_weaving_config - 30.0s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 34a24a9779064e241c58c4b8b4a11d3b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:44:27.477693: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:44:28.912783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 24.5s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8c3adbc20dbe4ee81f08ba27de82bbd2\n",
      "_____________________________calculate_score_from_weaving_config - 23.1s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 99dfec43e7f17791e6f2df76a7a70e68\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:44:42.806910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:44:49.195136: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:44:49.201994: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 45.8s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4dcc75170897119013feeb64f3fbd27d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:45:03.216522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:45:03.768809: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 45.1s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 07abd2242045258c8a9a955d0e85bae3\n",
      "_____________________________calculate_score_from_weaving_config - 46.6s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d8999a07f2d568f0793dd15ba9003104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 39.3s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 11c67c4253abb33673b5ecf48e48b4e5\n",
      "_____________________________calculate_score_from_weaving_config - 41.6s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 044a95b1c76b055d10a186e8ffc2cf5d\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:45:24.555017: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:45:29.349186: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:45:29.964471: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:45:38.716722: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:45:39.176680: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 37.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 75066cc5d1849da505321e134cf9b284\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 34.3s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c94f7db8a0badb1dce8abcb1c0b52081\n",
      "_____________________________calculate_score_from_weaving_config - 36.5s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f4e19ecc655f7bc6f921e79982452956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 30.3s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 993e1f118a52d8b45753e8061c45f2b7\n",
      "_____________________________calculate_score_from_weaving_config - 32.7s, 0.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1bf6f61e24ba8c291c5c1d187a55ad4c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:45:55.638794: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:45:57.111390: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 26.9s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8db9721fffe2f71d02817939ad7a1046\n",
      "_____________________________calculate_score_from_weaving_config - 25.1s, 0.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: aeee6e47145cc93ffb0adc22cef69def\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:46:12.417135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:46:17.788872: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:46:17.908150: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 48.9s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f1b8b9133d8432e5f4ebf700e917c6e9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:46:33.760737: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:46:35.146672: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 47.1s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 6ce4af47a8114b0a9963b2503e66354d\n",
      "_____________________________calculate_score_from_weaving_config - 48.8s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 65f370eb356e4d9633f91aa87dfd78eb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 41.1s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: cb59e9e261da88f26cda680532af5a38\n",
      "_____________________________calculate_score_from_weaving_config - 44.4s, 0.7min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b6ebd1453d7285b128443fcc46cb23da\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:46:55.729877: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:46:59.684114: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:47:00.015464: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:47:11.161555: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:47:11.978733: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 38.5s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d2ba75193b00a9e6b1bcd73da77efef6\n",
      "_____________________________calculate_score_from_weaving_config - 36.1s, 0.6min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 079ed7b0e553f43a2805823ceb0878b7\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "_____________________________calculate_score_from_weaving_config - 38.4s, 0.6min\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 33.4s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 31.1s, 0.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:47:25.819847: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:47:27.490945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 19.1s, 0.3min\n",
      "_____________________________calculate_score_from_weaving_config - 17.8s, 0.3min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = Parallel(n_jobs=5, return_as=\"list\")(\n",
    "    delayed(calculate_score_from_weaving_config_cached)(\n",
    "        weave_config,\n",
    "        # n_examples=4096,\n",
    "        n_examples=128,\n",
    "        split=\"validation\",\n",
    "    )\n",
    "    for weave_config in weave_configs\n",
    ")\n",
    "accuracies = [score[\"accuracy\"] for score in scores]\n",
    "\n",
    "\n",
    "records = []\n",
    "for weave_config, accuracy in zip(weave_configs, accuracies):\n",
    "    record = weave_config[\"metadata\"]\n",
    "    record[\"accuracy\"] = accuracy\n",
    "    records.append(record)\n",
    "df_big_grid = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='y', ylabel='x'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a heatmap of the accuracy with respect to the layer transitions\n",
    "# x and y are the layer numbers of the first and last layer of the transition\n",
    "# the color is the accuracy\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(\n",
    "    df_big_grid.pivot(index=\"x\", columns=\"y\", values=\"accuracy\"),\n",
    "    annot=True,\n",
    "    # fmt=\".0%\",\n",
    "    # do not show numbers in the heatmap\n",
    "    # fmt=\".0f\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar_kws={\"label\": \"Accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=512, split='validation')\n",
      "calculating score for weaving config md5sum: e628fef824418808d55b90b530c3cf12\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "2023-11-28 10:48:06.904444: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 38.2s, 0.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.861328125}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score\n",
    "best = df_big_grid[df_big_grid[\"accuracy\"] == df_big_grid[\"accuracy\"].max()]\n",
    "\n",
    "best.x.values[0], best.y.values[0]\n",
    "# get the weave config with the best score\n",
    "best_weave_config = weave_configs[df_big_grid[\"accuracy\"].idxmax()]\n",
    "\n",
    "# get the best score using more samples\n",
    "calculate_score_from_weaving_config_cached(\n",
    "    best_weave_config,\n",
    "    # n_examples=4096,\n",
    "    n_examples=512,\n",
    "    split=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_layers = get_model_config(model_id)[\"num_hidden_layers\"]\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(num_layers))\n",
    "\n",
    "weights = (\n",
    "    df_big_grid.pivot(index=\"x\", columns=\"y\", values=\"accuracy\").fillna(0).to_numpy()\n",
    ")\n",
    "max_weight = weights.max()\n",
    "\n",
    "for x in range(num_layers):\n",
    "    for y in range(num_layers):\n",
    "        # if the weight is > 0.7, add the edge\n",
    "        if weights[x][y] > max_weight - 0.038:\n",
    "            G.add_edge(x, y, weight=weights[x][y])\n",
    "\n",
    "# light blue nodes\n",
    "node_colors = [\"#b3cde3\"] * num_layers\n",
    "nx.draw(G, with_labels=True, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: [[0, 2, 2, 3, 4, 5, 7, 7, 9, 11], [0, 2, 3, 6, 7, 8, 9, 10, 8, 11], [0, 2, 2, 2, 2, 3, 6, 7, 8, 11], [0, 2, 3, 6, 5, 7, 9, 7, 8, 11], [0, 1, 2, 2, 2, 3, 3, 6, 9, 11]], 11: [[0, 2, 3, 6, 5, 3, 6, 5, 6, 9, 11], [0, 2, 2, 3, 4, 7, 2, 3, 6, 9, 11], [0, 2, 3, 1, 3, 4, 7, 5, 6, 9, 11], [0, 1, 3, 4, 2, 3, 4, 7, 9, 9, 11], [0, 2, 2, 3, 6, 9, 10, 8, 10, 9, 11]], 12: [[0, 2, 3, 6, 2, 3, 3, 6, 9, 10, 10, 11], [0, 1, 2, 2, 2, 3, 4, 7, 8, 9, 10, 11], [0, 1, 3, 3, 1, 3, 6, 2, 3, 6, 9, 11], [0, 2, 3, 2, 3, 6, 9, 7, 8, 10, 9, 11], [0, 2, 3, 1, 1, 1, 3, 3, 6, 6, 9, 11]], 13: [[0, 1, 3, 6, 7, 6, 2, 3, 4, 5, 7, 8, 11], [0, 2, 3, 2, 2, 2, 3, 3, 2, 3, 6, 9, 11], [0, 1, 2, 3, 1, 2, 3, 6, 2, 3, 6, 9, 11], [0, 1, 2, 2, 3, 4, 3, 4, 4, 6, 6, 9, 11], [0, 1, 3, 3, 4, 3, 3, 6, 9, 6, 6, 9, 11]], 14: [[0, 1, 1, 3, 2, 3, 6, 2, 2, 3, 4, 6, 9, 11], [0, 2, 2, 3, 4, 4, 3, 1, 3, 3, 4, 6, 9, 11], [0, 2, 2, 2, 2, 3, 4, 3, 6, 7, 8, 6, 9, 11], [0, 2, 2, 3, 1, 2, 2, 2, 2, 3, 4, 6, 9, 11], [0, 2, 3, 3, 2, 2, 3, 1, 3, 4, 5, 7, 8, 11]], 15: [[0, 1, 2, 2, 2, 3, 3, 1, 1, 3, 3, 6, 9, 10, 11], [0, 1, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 6, 9, 11], [0, 1, 1, 2, 3, 6, 6, 9, 8, 9, 8, 9, 9, 10, 11], [0, 2, 3, 6, 6, 5, 1, 3, 3, 4, 3, 4, 6, 9, 11], [0, 1, 1, 3, 6, 2, 3, 4, 3, 6, 5, 7, 7, 9, 11]], 16: [[0, 2, 3, 4, 4, 4, 7, 5, 5, 7, 3, 4, 5, 7, 9, 11], [0, 1, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 6, 9, 10, 11], [0, 1, 3, 1, 3, 3, 2, 2, 2, 3, 4, 6, 6, 6, 9, 11], [0, 2, 2, 3, 4, 2, 3, 3, 3, 3, 4, 4, 7, 6, 9, 11], [0, 1, 2, 3, 2, 3, 6, 5, 7, 4, 7, 8, 8, 9, 10, 11]], 17: [[0, 1, 1, 2, 2, 3, 4, 7, 9, 6, 6, 9, 5, 3, 6, 9, 11], [0, 2, 3, 1, 1, 2, 3, 6, 5, 7, 8, 10, 5, 6, 9, 8, 11], [0, 1, 2, 3, 1, 1, 1, 3, 6, 2, 2, 3, 6, 9, 9, 8, 11], [0, 1, 3, 4, 4, 7, 2, 2, 2, 3, 1, 1, 2, 3, 6, 9, 11], [0, 2, 3, 4, 5, 3, 4, 7, 9, 8, 8, 7, 7, 9, 8, 8, 11]], 18: [[0, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 6, 7, 9, 11], [0, 2, 2, 3, 4, 6, 6, 7, 2, 2, 3, 4, 7, 5, 4, 6, 9, 11], [0, 2, 2, 3, 1, 1, 3, 3, 6, 7, 2, 2, 3, 4, 3, 6, 9, 11], [0, 1, 2, 3, 4, 7, 4, 7, 4, 3, 2, 3, 6, 5, 6, 6, 9, 11], [0, 1, 3, 2, 2, 2, 2, 3, 6, 7, 6, 7, 9, 10, 6, 6, 9, 11]]}\n"
     ]
    }
   ],
   "source": [
    "# Sample trajectories\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "trajectories_by_length = {}\n",
    "for length in range(num_layers - 2, num_layers + 7):\n",
    "    trajectories = []\n",
    "    while len(trajectories) < 5:\n",
    "        trajectory = [0]\n",
    "        while trajectory[-1] != num_layers - 1:\n",
    "            # Assume uniform distribution over neighbors\n",
    "            trajectory.append(random.choice(list(G.neighbors(trajectory[-1]))))\n",
    "        if len(trajectory) == length:\n",
    "            trajectories.append(trajectory)\n",
    "    trajectories_by_length[length] = trajectories\n",
    "\n",
    "print(trajectories_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 10\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c8b76bbd44b8750fb132cf00712dbbc1\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b845f80391e73b592bbccb133378417c\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 13a4b604bb20b4a46109823af0c66d2f\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5489f779fa38d46dd145abf4b1ee0a40\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b1391690600e981e87c06d9bf8d9b8df\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:48:24.094768: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:25.841623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:25.855066: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:25.855893: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:25.864307: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 19.4s, 0.3min\n",
      "_____________________________calculate_score_from_weaving_config - 22.6s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 22.9s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 23.0s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 23.0s, 0.4min\n",
      "Length 11\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f47b494415fda0e112cb744b4261222b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4585cc835eb5ea485712abd0768b7a98\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: dcb65cf00f8f7bca04a50b34184ca1a9\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 52f25a5110fa9c9cfcd4c32cf18fe366\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 85907e370a5fcee1cdc8665085dd44f2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:48:48.361732: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:49.716184: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:49.728809: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:49.729174: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:48:49.738676: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 21.6s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 24.6s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 24.9s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 24.9s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 24.9s, 0.4min\n",
      "Length 12\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7c0a73744d2e5d01820a77a90c2ffe83\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4ac8893d143aab9aa4d8204dd8f13a96\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f5facb35d331133ffc63e58eed5c89da\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d54d9debd3f5393602bfe7ac9a2968f1\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f5d9dfbd0b2edc6ba7f7eeb255405892\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:49:15.408857: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:49:16.838755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:16.913405: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:16.917374: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:16.951815: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 25.0s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "Length 13\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0241f7724ead11620d9a6573d9a07577\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5593988dbec734e9e9a696d95be24d2c\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1a5bc9a276b3f13739d076c10bab593b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: f0217d5d39c64c1fe9419a8837997b08\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 53519b97729cc326402daeb6c77da1c8\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:49:43.386709: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:45.277281: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:45.444623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:45.458127: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:49:45.459141: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 25.2s, 0.4min\n",
      "_____________________________calculate_score_from_weaving_config - 28.6s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 28.7s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 29.0s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 29.0s, 0.5min\n",
      "Length 14\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 42c97d8191835a0f685b293fcee0b145\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 75237782452ac01e9cc43317358beda2\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: b224f2c80b27e24575db9906f7c4d3fa\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: de7fd952faa9ae7c89e5f9cc6d28ed89\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 87c81a36997781bc06b6a00daeedf206\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:50:13.640243: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:15.176038: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:15.176453: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:15.387713: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:15.504740: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 28.1s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 31.0s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 31.1s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 31.0s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 31.2s, 0.5min\n",
      "Length 15\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 4280fec65c0fbd5faf7ac3c5687e315c\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: e4660bf773b20d1f73649000feaace42\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: a653adbf55935dc65b8a9947b4e35190\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 9eccf79f56d12d2a858595fbe198f6d3\n",
      "calculating score for weaving config md5sum: 2e1ba38dff5429843bdc256c248b573a\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:50:45.902455: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 10:50:47.183385: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:47.631992: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:47.637727: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:50:47.700989: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 30.0s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 32.7s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 32.8s, 0.5min\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 32.9s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 32.9s, 0.5min\n",
      "Length 16\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 7d94f7960e0871aabbb9bd72d8513e4e\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 32d3f8d77343129cdcd1442a08486b61\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 09eb8c2da9bebad18272b5173b0dddc6\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: d8e66e56e78b805ae2dbb5c0181a49f5\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: a6e51c43ba1b19fb362a1675b3c834e5\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:51:19.736524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:21.274409: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:21.341597: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:21.345827: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:21.348016: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.1s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 34.6s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 34.6s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 34.9s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 35.0s, 0.6min\n",
      "Length 17\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: c8d34360a249047c2b743bf203b3de7e\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 27724d735d85b8a4f2ccbaa22db2261b\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 0e54a137b00cd3212f39e236c1038899\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 1e04931c5fd18ac926b961a9fd881694\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 5b2402500128ecc95938cf29c092b33a\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:51:55.985724: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:57.096056: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:57.372279: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:57.762384: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:51:57.787454: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 34.5s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 36.2s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 36.7s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 36.8s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 37.0s, 0.6min\n",
      "Length 18\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 84bd5ace26637464e6574ff9b7ecd4ef\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 436741f99eb0fb06867a816de689a2a2\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 8b3a0bc04fe554c6ef3040e53ed294bc\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: 861c16d5d91887011a377752ef8d3e14\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=128, split='validation')\n",
      "calculating score for weaving config md5sum: bb23a2223dedf8c31eb33f9d84673c64\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n",
      "Loading JeremiahZ/roberta-base-sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:330: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "2023-11-28 10:52:34.347220: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:52:35.746061: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:52:35.768027: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:52:36.137187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-11-28 10:52:36.263892: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [0]\n",
      "_____________________________calculate_score_from_weaving_config - 36.8s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 38.8s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 38.9s, 0.6min\n",
      "_____________________________calculate_score_from_weaving_config - 39.1s, 0.7min\n",
      "_____________________________calculate_score_from_weaving_config - 39.2s, 0.7min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trajectory</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>trajectory_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 2, 2, 3, 4, 5, 7, 7, 9, 11]</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 2, 3, 6, 7, 8, 9, 10, 8, 11]</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 2, 2, 2, 2, 3, 6, 7, 8, 11]</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 2, 3, 6, 5, 7, 9, 7, 8, 11]</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 2, 2, 3, 3, 6, 9, 11]</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 2, 3, 6, 5, 3, 6, 5, 6, 9, 11]</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 2, 2, 3, 4, 7, 2, 3, 6, 9, 11]</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 2, 3, 1, 3, 4, 7, 5, 6, 9, 11]</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 1, 3, 4, 2, 3, 4, 7, 9, 9, 11]</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 2, 2, 3, 6, 9, 10, 8, 10, 9, 11]</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0, 2, 3, 6, 2, 3, 3, 6, 9, 10, 10, 11]</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0, 1, 2, 2, 2, 3, 4, 7, 8, 9, 10, 11]</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0, 1, 3, 3, 1, 3, 6, 2, 3, 6, 9, 11]</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0, 2, 3, 2, 3, 6, 9, 7, 8, 10, 9, 11]</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0, 2, 3, 1, 1, 1, 3, 3, 6, 6, 9, 11]</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0, 1, 3, 6, 7, 6, 2, 3, 4, 5, 7, 8, 11]</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0, 2, 3, 2, 2, 2, 3, 3, 2, 3, 6, 9, 11]</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0, 1, 2, 3, 1, 2, 3, 6, 2, 3, 6, 9, 11]</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0, 1, 2, 2, 3, 4, 3, 4, 4, 6, 6, 9, 11]</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0, 1, 3, 3, 4, 3, 3, 6, 9, 6, 6, 9, 11]</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0, 1, 1, 3, 2, 3, 6, 2, 2, 3, 4, 6, 9, 11]</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0, 2, 2, 3, 4, 4, 3, 1, 3, 3, 4, 6, 9, 11]</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0, 2, 2, 2, 2, 3, 4, 3, 6, 7, 8, 6, 9, 11]</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0, 2, 2, 3, 1, 2, 2, 2, 2, 3, 4, 6, 9, 11]</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0, 2, 3, 3, 2, 2, 3, 1, 3, 4, 5, 7, 8, 11]</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0, 1, 2, 2, 2, 3, 3, 1, 1, 3, 3, 6, 9, 10, 11]</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0, 1, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 6, 9, 11]</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0, 1, 1, 2, 3, 6, 6, 9, 8, 9, 8, 9, 9, 10, 11]</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0, 2, 3, 6, 6, 5, 1, 3, 3, 4, 3, 4, 6, 9, 11]</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0, 1, 1, 3, 6, 2, 3, 4, 3, 6, 5, 7, 7, 9, 11]</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0, 2, 3, 4, 4, 4, 7, 5, 5, 7, 3, 4, 5, 7, 9, 11]</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0, 1, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 6, 9, 10,...</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0, 1, 3, 1, 3, 3, 2, 2, 2, 3, 4, 6, 6, 6, 9, 11]</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0, 2, 2, 3, 4, 2, 3, 3, 3, 3, 4, 4, 7, 6, 9, 11]</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0, 1, 2, 3, 2, 3, 6, 5, 7, 4, 7, 8, 8, 9, 10,...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0, 1, 1, 2, 2, 3, 4, 7, 9, 6, 6, 9, 5, 3, 6, ...</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0, 2, 3, 1, 1, 2, 3, 6, 5, 7, 8, 10, 5, 6, 9,...</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0, 1, 2, 3, 1, 1, 1, 3, 6, 2, 2, 3, 6, 9, 9, ...</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0, 1, 3, 4, 4, 7, 2, 2, 2, 3, 1, 1, 2, 3, 6, ...</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0, 2, 3, 4, 5, 3, 4, 7, 9, 8, 8, 7, 7, 9, 8, ...</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 6, ...</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0, 2, 2, 3, 4, 6, 6, 7, 2, 2, 3, 4, 7, 5, 4, ...</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0, 2, 2, 3, 1, 1, 3, 3, 6, 7, 2, 2, 3, 4, 3, ...</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0, 1, 2, 3, 4, 7, 4, 7, 4, 3, 2, 3, 6, 5, 6, ...</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0, 1, 3, 2, 2, 2, 2, 3, 6, 7, 6, 7, 9, 10, 6,...</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           trajectory  accuracy  \\\n",
       "0                     [0, 2, 2, 3, 4, 5, 7, 7, 9, 11]  0.718750   \n",
       "1                    [0, 2, 3, 6, 7, 8, 9, 10, 8, 11]  0.679688   \n",
       "2                     [0, 2, 2, 2, 2, 3, 6, 7, 8, 11]  0.562500   \n",
       "3                     [0, 2, 3, 6, 5, 7, 9, 7, 8, 11]  0.492188   \n",
       "4                     [0, 1, 2, 2, 2, 3, 3, 6, 9, 11]  0.546875   \n",
       "5                  [0, 2, 3, 6, 5, 3, 6, 5, 6, 9, 11]  0.531250   \n",
       "6                  [0, 2, 2, 3, 4, 7, 2, 3, 6, 9, 11]  0.601562   \n",
       "7                  [0, 2, 3, 1, 3, 4, 7, 5, 6, 9, 11]  0.781250   \n",
       "8                  [0, 1, 3, 4, 2, 3, 4, 7, 9, 9, 11]  0.765625   \n",
       "9                [0, 2, 2, 3, 6, 9, 10, 8, 10, 9, 11]  0.617188   \n",
       "10            [0, 2, 3, 6, 2, 3, 3, 6, 9, 10, 10, 11]  0.531250   \n",
       "11             [0, 1, 2, 2, 2, 3, 4, 7, 8, 9, 10, 11]  0.851562   \n",
       "12              [0, 1, 3, 3, 1, 3, 6, 2, 3, 6, 9, 11]  0.570312   \n",
       "13             [0, 2, 3, 2, 3, 6, 9, 7, 8, 10, 9, 11]  0.679688   \n",
       "14              [0, 2, 3, 1, 1, 1, 3, 3, 6, 6, 9, 11]  0.531250   \n",
       "15           [0, 1, 3, 6, 7, 6, 2, 3, 4, 5, 7, 8, 11]  0.617188   \n",
       "16           [0, 2, 3, 2, 2, 2, 3, 3, 2, 3, 6, 9, 11]  0.492188   \n",
       "17           [0, 1, 2, 3, 1, 2, 3, 6, 2, 3, 6, 9, 11]  0.601562   \n",
       "18           [0, 1, 2, 2, 3, 4, 3, 4, 4, 6, 6, 9, 11]  0.671875   \n",
       "19           [0, 1, 3, 3, 4, 3, 3, 6, 9, 6, 6, 9, 11]  0.742188   \n",
       "20        [0, 1, 1, 3, 2, 3, 6, 2, 2, 3, 4, 6, 9, 11]  0.531250   \n",
       "21        [0, 2, 2, 3, 4, 4, 3, 1, 3, 3, 4, 6, 9, 11]  0.539062   \n",
       "22        [0, 2, 2, 2, 2, 3, 4, 3, 6, 7, 8, 6, 9, 11]  0.523438   \n",
       "23        [0, 2, 2, 3, 1, 2, 2, 2, 2, 3, 4, 6, 9, 11]  0.554688   \n",
       "24        [0, 2, 3, 3, 2, 2, 3, 1, 3, 4, 5, 7, 8, 11]  0.515625   \n",
       "25    [0, 1, 2, 2, 2, 3, 3, 1, 1, 3, 3, 6, 9, 10, 11]  0.554688   \n",
       "26     [0, 1, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 6, 9, 11]  0.523438   \n",
       "27    [0, 1, 1, 2, 3, 6, 6, 9, 8, 9, 8, 9, 9, 10, 11]  0.773438   \n",
       "28     [0, 2, 3, 6, 6, 5, 1, 3, 3, 4, 3, 4, 6, 9, 11]  0.515625   \n",
       "29     [0, 1, 1, 3, 6, 2, 3, 4, 3, 6, 5, 7, 7, 9, 11]  0.632812   \n",
       "30  [0, 2, 3, 4, 4, 4, 7, 5, 5, 7, 3, 4, 5, 7, 9, 11]  0.703125   \n",
       "31  [0, 1, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 6, 9, 10,...  0.468750   \n",
       "32  [0, 1, 3, 1, 3, 3, 2, 2, 2, 3, 4, 6, 6, 6, 9, 11]  0.515625   \n",
       "33  [0, 2, 2, 3, 4, 2, 3, 3, 3, 3, 4, 4, 7, 6, 9, 11]  0.429688   \n",
       "34  [0, 1, 2, 3, 2, 3, 6, 5, 7, 4, 7, 8, 8, 9, 10,...  0.750000   \n",
       "35  [0, 1, 1, 2, 2, 3, 4, 7, 9, 6, 6, 9, 5, 3, 6, ...  0.726562   \n",
       "36  [0, 2, 3, 1, 1, 2, 3, 6, 5, 7, 8, 10, 5, 6, 9,...  0.617188   \n",
       "37  [0, 1, 2, 3, 1, 1, 1, 3, 6, 2, 2, 3, 6, 9, 9, ...  0.632812   \n",
       "38  [0, 1, 3, 4, 4, 7, 2, 2, 2, 3, 1, 1, 2, 3, 6, ...  0.523438   \n",
       "39  [0, 2, 3, 4, 5, 3, 4, 7, 9, 8, 8, 7, 7, 9, 8, ...  0.585938   \n",
       "40  [0, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 6, ...  0.507812   \n",
       "41  [0, 2, 2, 3, 4, 6, 6, 7, 2, 2, 3, 4, 7, 5, 4, ...  0.492188   \n",
       "42  [0, 2, 2, 3, 1, 1, 3, 3, 6, 7, 2, 2, 3, 4, 3, ...  0.546875   \n",
       "43  [0, 1, 2, 3, 4, 7, 4, 7, 4, 3, 2, 3, 6, 5, 6, ...  0.804688   \n",
       "44  [0, 1, 3, 2, 2, 2, 2, 3, 6, 7, 6, 7, 9, 10, 6,...  0.593750   \n",
       "\n",
       "    trajectory_length  \n",
       "0                  10  \n",
       "1                  10  \n",
       "2                  10  \n",
       "3                  10  \n",
       "4                  10  \n",
       "5                  11  \n",
       "6                  11  \n",
       "7                  11  \n",
       "8                  11  \n",
       "9                  11  \n",
       "10                 12  \n",
       "11                 12  \n",
       "12                 12  \n",
       "13                 12  \n",
       "14                 12  \n",
       "15                 13  \n",
       "16                 13  \n",
       "17                 13  \n",
       "18                 13  \n",
       "19                 13  \n",
       "20                 14  \n",
       "21                 14  \n",
       "22                 14  \n",
       "23                 14  \n",
       "24                 14  \n",
       "25                 15  \n",
       "26                 15  \n",
       "27                 15  \n",
       "28                 15  \n",
       "29                 15  \n",
       "30                 16  \n",
       "31                 16  \n",
       "32                 16  \n",
       "33                 16  \n",
       "34                 16  \n",
       "35                 17  \n",
       "36                 17  \n",
       "37                 17  \n",
       "38                 17  \n",
       "39                 17  \n",
       "40                 18  \n",
       "41                 18  \n",
       "42                 18  \n",
       "43                 18  \n",
       "44                 18  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for length, trajectories in trajectories_by_length.items():\n",
    "    print(f\"Length {length}\")\n",
    "    weave_configs = list(\n",
    "        transitions_weave_configs_iter(model_id, trajectories=trajectories)\n",
    "    )\n",
    "\n",
    "    scores = Parallel(n_jobs=5, return_as=\"list\")(\n",
    "        delayed(calculate_score_from_weaving_config_cached)(\n",
    "            weave_config,\n",
    "            # n_examples=4096,\n",
    "            n_examples=128,\n",
    "            split=\"validation\",\n",
    "        )\n",
    "        for weave_config in weave_configs\n",
    "    )\n",
    "    accuracies = [score[\"accuracy\"] for score in scores]\n",
    "\n",
    "    for trajectory, accuracy in zip(trajectories, accuracies):\n",
    "        record = {}\n",
    "        record[\"trajectory\"] = trajectory\n",
    "        record[\"accuracy\"] = accuracy\n",
    "        record[\"trajectory_length\"] = len(trajectory)\n",
    "        records.append(record)\n",
    "df_transitions = pd.DataFrame.from_records(records)\n",
    "df_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='trajectory_length', ylabel='accuracy'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a violin plot of the distribution of accuracies for each trajectory length\n",
    "sns.violinplot(\n",
    "    data=df_transitions,\n",
    "    x=\"trajectory_length\",\n",
    "    y=\"accuracy\",\n",
    "    inner=None,\n",
    "    color=\".8\",\n",
    "    cut=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "418d7ffbf17f07fb7db812548652bd547b7709e294d6b5c17ab307303352fd7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
