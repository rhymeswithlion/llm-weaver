{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the weaving code on the base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: visions 0.7.5 does not provide the extra 'type-image-path'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "\n",
    "! pip install -q joblib  # joblib for memoizing functions\n",
    "! pip install -q ipywidgets widgetsnbextension pandas-profiling # IProgress for progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model_merging to the python path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "model_merging_base = os.path.abspath(\"../model_merging/\")\n",
    "# assert it exist\n",
    "assert os.path.exists(model_merging_base)\n",
    "if model_merging_base not in sys.path:\n",
    "    sys.path.append(model_merging_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib for caching and distributed computing\n",
    "from math import sqrt\n",
    "\n",
    "from joblib import Memory, Parallel, delayed\n",
    "\n",
    "# memory = Memory(location=\"cache\", verbose=10)\n",
    "memory = Memory(location=\"cache\", verbose=0)\n",
    "\n",
    "parallel = Parallel(n_jobs=2, return_as=\"generator\")\n",
    "output_generator = parallel(delayed(sqrt)(i**2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and cached functions\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from llm_weaver import (\n",
    "    calculate_score_from_weaving_config,\n",
    "    get_score_from_named_model,\n",
    "    test_weaver,\n",
    ")\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "calculate_score_from_weaving_config_cached = memory.cache(\n",
    "    calculate_score_from_weaving_config\n",
    ")\n",
    "test_weaver_cached = memory.cache(test_weaver)\n",
    "\n",
    "get_score_from_named_model_cached = memory.cache(get_score_from_named_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Test weaving code\n",
    "\n",
    "This test makes sure that our score when using the weaver to reconstruct a model from all its parts get the same evaluation score as the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textattack/roberta-base-RTE</td>\n",
       "      <td>({'accuracy': 0.7}, {'accuracy': 0.7})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>textattack/roberta-base-MNLI</td>\n",
       "      <td>({'accuracy': 0.3}, {'accuracy': 0.3})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>howey/roberta-large-rte</td>\n",
       "      <td>({'accuracy': 0.65}, {'accuracy': 0.65})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>howey/roberta-large-mnli</td>\n",
       "      <td>({'accuracy': 0.68}, {'accuracy': 0.68})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>howey/roberta-large-qnli</td>\n",
       "      <td>({'accuracy': 0.86}, {'accuracy': 0.86})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>howey/roberta-large-sst2</td>\n",
       "      <td>({'accuracy': 0.77}, {'accuracy': 0.77})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>howey/roberta-large-cola</td>\n",
       "      <td>({'matthews_correlation': 0.19169538058831714}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>howey/roberta-large-mrpc</td>\n",
       "      <td>({'accuracy': 0.61, 'f1': 0.6486486486486487},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>howey/roberta-large-qqp</td>\n",
       "      <td>({'accuracy': 0.77, 'f1': 0.5490196078431372},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JeremiahZ/roberta-base-rte</td>\n",
       "      <td>({'accuracy': 0.61}, {'accuracy': 0.61})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JeremiahZ/roberta-base-mnli</td>\n",
       "      <td>({'accuracy': 0.83}, {'accuracy': 0.83})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JeremiahZ/roberta-base-qnli</td>\n",
       "      <td>({'accuracy': 0.82}, {'accuracy': 0.82})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JeremiahZ/roberta-base-sst2</td>\n",
       "      <td>({'accuracy': 0.89}, {'accuracy': 0.89})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JeremiahZ/roberta-base-cola</td>\n",
       "      <td>({'matthews_correlation': 0.15285569591066622}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JeremiahZ/roberta-base-mrpc</td>\n",
       "      <td>({'accuracy': 0.33, 'f1': 0.10666666666666666}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JeremiahZ/roberta-base-qqp</td>\n",
       "      <td>({'accuracy': 0.79, 'f1': 0.7341772151898734},...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_id  \\\n",
       "0    textattack/roberta-base-RTE   \n",
       "1   textattack/roberta-base-MNLI   \n",
       "2        howey/roberta-large-rte   \n",
       "3       howey/roberta-large-mnli   \n",
       "4       howey/roberta-large-qnli   \n",
       "5       howey/roberta-large-sst2   \n",
       "6       howey/roberta-large-cola   \n",
       "7       howey/roberta-large-mrpc   \n",
       "8        howey/roberta-large-qqp   \n",
       "9     JeremiahZ/roberta-base-rte   \n",
       "10   JeremiahZ/roberta-base-mnli   \n",
       "11   JeremiahZ/roberta-base-qnli   \n",
       "12   JeremiahZ/roberta-base-sst2   \n",
       "13   JeremiahZ/roberta-base-cola   \n",
       "14   JeremiahZ/roberta-base-mrpc   \n",
       "15    JeremiahZ/roberta-base-qqp   \n",
       "\n",
       "                                              results  \n",
       "0              ({'accuracy': 0.7}, {'accuracy': 0.7})  \n",
       "1              ({'accuracy': 0.3}, {'accuracy': 0.3})  \n",
       "2            ({'accuracy': 0.65}, {'accuracy': 0.65})  \n",
       "3            ({'accuracy': 0.68}, {'accuracy': 0.68})  \n",
       "4            ({'accuracy': 0.86}, {'accuracy': 0.86})  \n",
       "5            ({'accuracy': 0.77}, {'accuracy': 0.77})  \n",
       "6   ({'matthews_correlation': 0.19169538058831714}...  \n",
       "7   ({'accuracy': 0.61, 'f1': 0.6486486486486487},...  \n",
       "8   ({'accuracy': 0.77, 'f1': 0.5490196078431372},...  \n",
       "9            ({'accuracy': 0.61}, {'accuracy': 0.61})  \n",
       "10           ({'accuracy': 0.83}, {'accuracy': 0.83})  \n",
       "11           ({'accuracy': 0.82}, {'accuracy': 0.82})  \n",
       "12           ({'accuracy': 0.89}, {'accuracy': 0.89})  \n",
       "13  ({'matthews_correlation': 0.15285569591066622}...  \n",
       "14  ({'accuracy': 0.33, 'f1': 0.10666666666666666}...  \n",
       "15  ({'accuracy': 0.79, 'f1': 0.7341772151898734},...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ids = [\n",
    "    \"textattack/roberta-base-RTE\",\n",
    "    \"textattack/roberta-base-MNLI\",  # <--- this one has a very low score\n",
    "    \"howey/roberta-large-rte\",\n",
    "    \"howey/roberta-large-mnli\",\n",
    "    \"howey/roberta-large-qnli\",\n",
    "    \"howey/roberta-large-sst2\",\n",
    "    \"howey/roberta-large-cola\",\n",
    "    \"howey/roberta-large-mrpc\",\n",
    "    \"howey/roberta-large-qqp\",\n",
    "    # \"howey/roberta-large-stsb\",\n",
    "    \"JeremiahZ/roberta-base-rte\",\n",
    "    \"JeremiahZ/roberta-base-mnli\",\n",
    "    \"JeremiahZ/roberta-base-qnli\",\n",
    "    \"JeremiahZ/roberta-base-sst2\",\n",
    "    \"JeremiahZ/roberta-base-cola\",\n",
    "    \"JeremiahZ/roberta-base-mrpc\",\n",
    "    \"JeremiahZ/roberta-base-qqp\",\n",
    "    # \"JeremiahZ/roberta-base-stsb\",\n",
    "    # \"l-yohai/bigbird-roberta-base-mnli\",\n",
    "    # \"howey/roberta-large-squad2\",\n",
    "]\n",
    "# textattack/roberta-base-RTE ({'accuracy': 0.7}, {'accuracy': 0.7})\n",
    "# textattack/roberta-base-MNLI ({'accuracy': 0.3}, {'accuracy': 0.3})\n",
    "# howey/roberta-large-rte ({'accuracy': 0.65}, {'accuracy': 0.65})\n",
    "# howey/roberta-large-mnli ({'accuracy': 0.68}, {'accuracy': 0.68})\n",
    "# howey/roberta-large-qnli ({'accuracy': 0.86}, {'accuracy': 0.86})\n",
    "# howey/roberta-large-sst2 ({'accuracy': 0.77}, {'accuracy': 0.77})\n",
    "# howey/roberta-large-cola ({'matthews_correlation': 0.19169538058831714}, {'matthews_correlation': 0.19169538058831714})\n",
    "# howey/roberta-large-mrpc ({'accuracy': 0.61, 'f1': 0.6486486486486487}, {'accuracy': 0.61, 'f1': 0.6486486486486487})\n",
    "# howey/roberta-large-qqp ({'accuracy': 0.77, 'f1': 0.5490196078431372}, {'accuracy': 0.77, 'f1': 0.5490196078431372})\n",
    "# JeremiahZ/roberta-base-rte ({'accuracy': 0.61}, {'accuracy': 0.61})\n",
    "# JeremiahZ/roberta-base-mnli ({'accuracy': 0.83}, {'accuracy': 0.83})\n",
    "# JeremiahZ/roberta-base-qnli ({'accuracy': 0.82}, {'accuracy': 0.82})\n",
    "# JeremiahZ/roberta-base-sst2 ({'accuracy': 0.89}, {'accuracy': 0.89})\n",
    "# JeremiahZ/roberta-base-cola ({'matthews_correlation': 0.15285569591066622}, {'matthews_correlation': 0.15285569591066622})\n",
    "# JeremiahZ/roberta-base-mrpc ({'accuracy': 0.33, 'f1': 0.10666666666666666}, {'accuracy': 0.33, 'f1': 0.10666666666666666})\n",
    "# JeremiahZ/roberta-base-qqp ({'accuracy': 0.79, 'f1': 0.7341772151898734}, {'accuracy': 0.79, 'f1': 0.7341772151898734})\n",
    "\n",
    "\n",
    "records = []\n",
    "for model_id in model_ids:\n",
    "    records.append(dict(model_id=model_id, results=str(test_weaver_cached(model_id))))\n",
    "\n",
    "weaving_test_results_df = pd.DataFrame(records)\n",
    "weaving_test_results_df.to_csv(\"test-weaving-on-base-models.weaving_test_results.csv\")\n",
    "weaving_test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step get original model baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 1537.71it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1681.76it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1742.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 74.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>split</th>\n",
       "      <th>n_examples</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>matthews_correlation</th>\n",
       "      <th>f1</th>\n",
       "      <th>task</th>\n",
       "      <th>roberta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>JeremiahZ/roberta-base-cola</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JeremiahZ/roberta-base-cola</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.452776</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>JeremiahZ/roberta-base-cola</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.172932</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>howey/roberta-large-cola</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>howey/roberta-large-cola</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.451394</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>howey/roberta-large-cola</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td></td>\n",
       "      <td>0.235292</td>\n",
       "      <td></td>\n",
       "      <td>cola</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>textattack/roberta-base-MNLI</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.296875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>JeremiahZ/roberta-base-mnli</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.339844</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>textattack/roberta-base-MNLI</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.234375</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JeremiahZ/roberta-base-mnli</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960938</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>textattack/roberta-base-MNLI</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.265625</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JeremiahZ/roberta-base-mnli</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.855469</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>howey/roberta-large-mnli</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.324219</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>howey/roberta-large-mnli</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8125</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>howey/roberta-large-mnli</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.707031</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>JeremiahZ/roberta-base-mrpc</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.035156</td>\n",
       "      <td></td>\n",
       "      <td>0.067925</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JeremiahZ/roberta-base-mrpc</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.339844</td>\n",
       "      <td></td>\n",
       "      <td>0.076503</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JeremiahZ/roberta-base-mrpc</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.328125</td>\n",
       "      <td></td>\n",
       "      <td>0.085106</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>howey/roberta-large-mrpc</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.347656</td>\n",
       "      <td></td>\n",
       "      <td>0.515942</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>howey/roberta-large-mrpc</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.632812</td>\n",
       "      <td></td>\n",
       "      <td>0.635659</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>howey/roberta-large-mrpc</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.644531</td>\n",
       "      <td></td>\n",
       "      <td>0.678445</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>JeremiahZ/roberta-base-qnli</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.492188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JeremiahZ/roberta-base-qnli</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.914062</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JeremiahZ/roberta-base-qnli</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.835938</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>howey/roberta-large-qnli</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.476562</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>howey/roberta-large-qnli</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960938</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>howey/roberta-large-qnli</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.886719</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>qnli</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>JeremiahZ/roberta-base-qqp</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.292969</td>\n",
       "      <td></td>\n",
       "      <td>0.453172</td>\n",
       "      <td>qqp</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JeremiahZ/roberta-base-qqp</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.875</td>\n",
       "      <td></td>\n",
       "      <td>0.854545</td>\n",
       "      <td>qqp</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>JeremiahZ/roberta-base-qqp</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.847656</td>\n",
       "      <td></td>\n",
       "      <td>0.797927</td>\n",
       "      <td>qqp</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>howey/roberta-large-qqp</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.085938</td>\n",
       "      <td></td>\n",
       "      <td>0.158273</td>\n",
       "      <td>qqp</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>howey/roberta-large-qqp</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.769531</td>\n",
       "      <td></td>\n",
       "      <td>0.598639</td>\n",
       "      <td>qqp</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>howey/roberta-large-qqp</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.78125</td>\n",
       "      <td></td>\n",
       "      <td>0.575758</td>\n",
       "      <td>qqp</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>textattack/roberta-base-RTE</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.617188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>JeremiahZ/roberta-base-rte</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.796875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textattack/roberta-base-RTE</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.796875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JeremiahZ/roberta-base-rte</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.660156</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>textattack/roberta-base-RTE</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.726562</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JeremiahZ/roberta-base-rte</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.621094</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>howey/roberta-large-rte</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>howey/roberta-large-rte</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.691406</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>howey/roberta-large-rte</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.644531</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rte</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>JeremiahZ/roberta-base-sst2</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.433594</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JeremiahZ/roberta-base-sst2</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.738281</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JeremiahZ/roberta-base-sst2</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.867188</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>howey/roberta-large-sst2</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>howey/roberta-large-sst2</td>\n",
       "      <td>train</td>\n",
       "      <td>256</td>\n",
       "      <td>0.75</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>howey/roberta-large-sst2</td>\n",
       "      <td>validation</td>\n",
       "      <td>256</td>\n",
       "      <td>0.828125</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sst-2</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_id       split  n_examples  accuracy  \\\n",
       "45   JeremiahZ/roberta-base-cola        test         256             \n",
       "13   JeremiahZ/roberta-base-cola       train         256             \n",
       "29   JeremiahZ/roberta-base-cola  validation         256             \n",
       "38      howey/roberta-large-cola        test         256             \n",
       "6       howey/roberta-large-cola       train         256             \n",
       "22      howey/roberta-large-cola  validation         256             \n",
       "33  textattack/roberta-base-MNLI        test         256  0.296875   \n",
       "42   JeremiahZ/roberta-base-mnli        test         256  0.339844   \n",
       "1   textattack/roberta-base-MNLI       train         256  0.234375   \n",
       "10   JeremiahZ/roberta-base-mnli       train         256  0.960938   \n",
       "17  textattack/roberta-base-MNLI  validation         256  0.265625   \n",
       "26   JeremiahZ/roberta-base-mnli  validation         256  0.855469   \n",
       "35      howey/roberta-large-mnli        test         256  0.324219   \n",
       "3       howey/roberta-large-mnli       train         256    0.8125   \n",
       "19      howey/roberta-large-mnli  validation         256  0.707031   \n",
       "46   JeremiahZ/roberta-base-mrpc        test         256  0.035156   \n",
       "14   JeremiahZ/roberta-base-mrpc       train         256  0.339844   \n",
       "30   JeremiahZ/roberta-base-mrpc  validation         256  0.328125   \n",
       "39      howey/roberta-large-mrpc        test         256  0.347656   \n",
       "7       howey/roberta-large-mrpc       train         256  0.632812   \n",
       "23      howey/roberta-large-mrpc  validation         256  0.644531   \n",
       "43   JeremiahZ/roberta-base-qnli        test         256  0.492188   \n",
       "11   JeremiahZ/roberta-base-qnli       train         256  0.914062   \n",
       "27   JeremiahZ/roberta-base-qnli  validation         256  0.835938   \n",
       "36      howey/roberta-large-qnli        test         256  0.476562   \n",
       "4       howey/roberta-large-qnli       train         256  0.960938   \n",
       "20      howey/roberta-large-qnli  validation         256  0.886719   \n",
       "47    JeremiahZ/roberta-base-qqp        test         256  0.292969   \n",
       "15    JeremiahZ/roberta-base-qqp       train         256     0.875   \n",
       "31    JeremiahZ/roberta-base-qqp  validation         256  0.847656   \n",
       "40       howey/roberta-large-qqp        test         256  0.085938   \n",
       "8        howey/roberta-large-qqp       train         256  0.769531   \n",
       "24       howey/roberta-large-qqp  validation         256   0.78125   \n",
       "32   textattack/roberta-base-RTE        test         256  0.617188   \n",
       "41    JeremiahZ/roberta-base-rte        test         256  0.796875   \n",
       "0    textattack/roberta-base-RTE       train         256  0.796875   \n",
       "9     JeremiahZ/roberta-base-rte       train         256  0.660156   \n",
       "16   textattack/roberta-base-RTE  validation         256  0.726562   \n",
       "25    JeremiahZ/roberta-base-rte  validation         256  0.621094   \n",
       "34       howey/roberta-large-rte        test         256      0.25   \n",
       "2        howey/roberta-large-rte       train         256  0.691406   \n",
       "18       howey/roberta-large-rte  validation         256  0.644531   \n",
       "44   JeremiahZ/roberta-base-sst2        test         256  0.433594   \n",
       "12   JeremiahZ/roberta-base-sst2       train         256  0.738281   \n",
       "28   JeremiahZ/roberta-base-sst2  validation         256  0.867188   \n",
       "37      howey/roberta-large-sst2        test         256    0.6875   \n",
       "5       howey/roberta-large-sst2       train         256      0.75   \n",
       "21      howey/roberta-large-sst2  validation         256  0.828125   \n",
       "\n",
       "   matthews_correlation        f1   task roberta  \n",
       "45                  0.0             cola    base  \n",
       "13             0.452776             cola    base  \n",
       "29             0.172932             cola    base  \n",
       "38                  0.0             cola   large  \n",
       "6              0.451394             cola   large  \n",
       "22             0.235292             cola   large  \n",
       "33                                  mnli    base  \n",
       "42                                  mnli    base  \n",
       "1                                   mnli    base  \n",
       "10                                  mnli    base  \n",
       "17                                  mnli    base  \n",
       "26                                  mnli    base  \n",
       "35                                  mnli   large  \n",
       "3                                   mnli   large  \n",
       "19                                  mnli   large  \n",
       "46                       0.067925   mrpc    base  \n",
       "14                       0.076503   mrpc    base  \n",
       "30                       0.085106   mrpc    base  \n",
       "39                       0.515942   mrpc   large  \n",
       "7                        0.635659   mrpc   large  \n",
       "23                       0.678445   mrpc   large  \n",
       "43                                  qnli    base  \n",
       "11                                  qnli    base  \n",
       "27                                  qnli    base  \n",
       "36                                  qnli   large  \n",
       "4                                   qnli   large  \n",
       "20                                  qnli   large  \n",
       "47                       0.453172    qqp    base  \n",
       "15                       0.854545    qqp    base  \n",
       "31                       0.797927    qqp    base  \n",
       "40                       0.158273    qqp   large  \n",
       "8                        0.598639    qqp   large  \n",
       "24                       0.575758    qqp   large  \n",
       "32                                   rte    base  \n",
       "41                                   rte    base  \n",
       "0                                    rte    base  \n",
       "9                                    rte    base  \n",
       "16                                   rte    base  \n",
       "25                                   rte    base  \n",
       "34                                   rte   large  \n",
       "2                                    rte   large  \n",
       "18                                   rte   large  \n",
       "44                                 sst-2    base  \n",
       "12                                 sst-2    base  \n",
       "28                                 sst-2    base  \n",
       "37                                 sst-2   large  \n",
       "5                                  sst-2   large  \n",
       "21                                 sst-2   large  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_weaver import normalize_glue_task_name\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_examples = 256\n",
    "\n",
    "records = []\n",
    "for split in tqdm([\"train\", \"validation\", \"test\"]):\n",
    "    for model_id in tqdm(model_ids):\n",
    "        records.append(\n",
    "            {\n",
    "                \"model_id\": model_id,\n",
    "                \"split\": split,\n",
    "                \"score\": get_score_from_named_model_cached(\n",
    "                    model_id=model_id,\n",
    "                    split=split,\n",
    "                    n_examples=n_examples,\n",
    "                    max_length=128,\n",
    "                    batch_size=128,\n",
    "                ),\n",
    "                \"n_examples\": n_examples,\n",
    "            }\n",
    "        )\n",
    "import pandas as pd\n",
    "\n",
    "# Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
    "df = pd.DataFrame.from_records(records)\n",
    "df = df.join(pd.json_normalize(df[\"score\"])).drop(columns=[\"score\"])\n",
    "df[\"task\"] = df[\"model_id\"].apply(normalize_glue_task_name)\n",
    "df[\"roberta\"] = df[\"model_id\"].apply(lambda x: \"large\" if \"large\" in x else \"base\")\n",
    "# df = df[df[\"split\"] == \"train\"]\n",
    "# df = df[~df[\"accuracy\"].isna()]\n",
    "df = df.sort_values([\"task\", \"roberta\", \"split\"])\n",
    "# replace nan with ''\n",
    "df = df.fillna(\"\")\n",
    "df.to_csv(\"test-weaving-on-base-models.original-scores.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
