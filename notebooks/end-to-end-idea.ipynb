{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up blank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# create target model configuration\n",
    "target_model_config = {\n",
    "  \"architectures\": [\n",
    "    \"RobertaForSequenceClassification\"\n",
    "  ],\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"bos_token_id\": 0,\n",
    "  \"classifier_dropout\": None,\n",
    "  \"eos_token_id\": 2,\n",
    "  \"finetuning_task\": \"glue:rte\",\n",
    "  \"gradient_checkpointing\": False,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 514,\n",
    "  \"model_type\": \"roberta\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 15,\n",
    "  \"pad_token_id\": 1,\n",
    "  \"position_embedding_type\": \"absolute\",\n",
    "  \"transformers_version\": \"4.35.0\",\n",
    "  \"type_vocab_size\": 1,\n",
    "  \"use_cache\": True,\n",
    "  \"vocab_size\": 50265\n",
    "}\n",
    "#create blank model\n",
    "from transformers.models.roberta.modeling_tf_roberta import TFRobertaForSequenceClassification\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "new_config = RobertaConfig(**target_model_config)\n",
    "blank_model = TFRobertaForSequenceClassification(new_config)\n",
    "blank_model.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_model.save_pretrained('blank_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define weave pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_model_template': './blank_model',\n",
       " 'layer_assignments': [{'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 0}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 0}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 1}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 4}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 4}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 4}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 6}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 6}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 9}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 8}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 9}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 11}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-MNLI',\n",
       "    'hidden_layer_number': 11}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 11}},\n",
       "  {'type': 'SingleLayer',\n",
       "   'params': {'donor': 'textattack/roberta-base-RTE',\n",
       "    'hidden_layer_number': 11}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from random import randint\n",
    "# generate model weaving configuration\n",
    "model_weaving_config = {\n",
    "    # The task (i.e. the classification head should match the task at hand)\n",
    "    \"target_model_template\": \"./blank_model\",\n",
    "    # layer assignments\n",
    "    \"layer_assignments\": [\n",
    "        {\n",
    "            \"type\": \"SingleLayer\",\n",
    "            \"params\": {\n",
    "                # Pick one model randomly, p=0.5\n",
    "                \"donor\": [\"textattack/roberta-base-MNLI\",\n",
    "                          \"textattack/roberta-base-RTE\"][randint(0, 1)],\n",
    "                # Pick a layer within [i-1,i+1], keeping it between 0 and 11\n",
    "                \"hidden_layer_number\": min(11, max(0, randint(i - 1,i + 1))),\n",
    "            },\n",
    "        } for i in range(15)\n",
    "    ],\n",
    "}\n",
    "\n",
    "model_weaving_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llm_weaver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/marencordts/Documents/GitHub/2023-fall-cs-194-294-merging-llms/notebooks/end-to-end-idea.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marencordts/Documents/GitHub/2023-fall-cs-194-294-merging-llms/notebooks/end-to-end-idea.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllm_weaver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mweave\u001b[39;00m \u001b[39mimport\u001b[39;00m weave_models\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marencordts/Documents/GitHub/2023-fall-cs-194-294-merging-llms/notebooks/end-to-end-idea.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m weaved_model \u001b[39m=\u001b[39m weave_models(target_model_template\u001b[39m=\u001b[39mblank_model, layer_assignments\u001b[39m=\u001b[39mmodel_weaving_config[\u001b[39m\"\u001b[39m\u001b[39mlayer_assignments\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_weaver'"
     ]
    }
   ],
   "source": [
    "from llm_weaver.weave import weave_models\n",
    "\n",
    "weaved_model = weave_models(target_model_template=blank_model, layer_assignments=model_weaving_config[\"layer_assignments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaved_model.save_pretrained('weaved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from absl import app, flags\n",
    "from transformers.data.processors import glue as hf_glue\n",
    "# Example import statement assuming 'evaluation' is a module within 'model_merging'\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string(\"glue_task_weave_model\", \"rte\", \"GLUE task for evaluation\")\n",
    "#flags.DEFINE_string(\"split_weave_model\", \"validation\", \"Data split for evaluation\")\n",
    "#flags.DEFINE_integer(\"n_examples_weave_model\", 1000, \"Number of examples to evaluate\")\n",
    "#flags.DEFINE_integer(\"batch_size_weave_model\", 32, \"Batch size for evaluation\")\n",
    "#flags.DEFINE_integer(\"sequence_length_weave_model\", 128, \"Maximum sequence length\")\n",
    "#flags.DEFINE_string(\"favor_target_model_weave_model\", \"accuracy\", \"Favor target model based on the metric (e.g., 'accuracy')\")\n",
    "#flags.DEFINE_boolean(\"normalize_fishers_weave_model\", True, \"Normalize Fisher scores\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#from model_merging import data\n",
    "from model_merging.model_merging import evaluation\n",
    "from model_merging.model_merging.evaluation import load_metric_for_glue_task, evaluate_model\n",
    "#from model_merging.evaluation import load_metric_for_glue_task, evaluate_model\n",
    "\n",
    "#from model_merging import hdf5_util\n",
    "#from model_merging import merging\n",
    "def _to_tfds_task_name(task, split):\n",
    "    if task == \"sts-b\":\n",
    "        task = \"stsb\"\n",
    "    elif task == \"sst-2\":\n",
    "        task = \"sst2\"\n",
    "    elif task == \"mnli\" and split != \"train\":\n",
    "        task = \"mnli_matched\"\n",
    "    elif task == \"mnli-mm\" and split != \"train\":\n",
    "        task = \"mnli_mismatched\"\n",
    "    return task\n",
    "\n",
    "_STSB_MIN = 0\n",
    "_STSB_MAX = 5\n",
    "_STSB_NUM_BINS = 5 * (_STSB_MAX - _STSB_MIN)\n",
    "\n",
    "def _convert_dataset_to_features(\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    max_length,\n",
    "    task,\n",
    "):\n",
    "    \"\"\"Note that this is only for single examples; won't work with batched inputs.\"\"\"\n",
    "    pad_token = tokenizer.pad_token_id\n",
    "    # NOTE: Not sure if this is correct, but it matches up for BERT. RoBERTa does\n",
    "    # not appear to use token types\n",
    "    pad_token_segment_id = tokenizer.pad_token_type_id\n",
    "    _glue_processors = hf_glue.glue_processors\n",
    "    _glue_output_modes = hf_glue.glue_output_modes\n",
    "    processor = _glue_processors[task]()\n",
    "    output_mode = _glue_output_modes[task]\n",
    "\n",
    "    if task == \"sts-b\":\n",
    "        # STS-B regression\n",
    "        stsb_bins = np.linspace(_STSB_MIN, _STSB_MAX, num=_STSB_NUM_BINS + 1)\n",
    "        stsb_bins = stsb_bins[1:-1]\n",
    "    else:\n",
    "        label_list = processor.get_labels()\n",
    "        label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "\n",
    "def load_glue_dataset(task: str, split: str, tokenizer, max_length: int):\n",
    "    tfds_task = _to_tfds_task_name(task, split)\n",
    "    ds = tf.load(f\"glue/{tfds_task}\", split=split)\n",
    "    ds = _convert_dataset_to_features(\n",
    "        ds,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        task,\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "def main(_):\n",
    "    # Load the weaved model\n",
    "    weaved_model = TFRobertaForSequenceClassification.from_pretrained('weaved_model')\n",
    "\n",
    "    # Load the dataset\n",
    "    ds = load_glue_dataset(\n",
    "        task=FLAGS.glue_task,\n",
    "        split=FLAGS.split,\n",
    "        tokenizer=weaved_model.tokenizer,\n",
    "        max_length=FLAGS.sequence_length,\n",
    "    )\n",
    "    ds = ds.take(FLAGS.n_examples).batch(FLAGS.batch_size)\n",
    "\n",
    "    # Load metrics\n",
    "    metric = evaluation.load_metric_for_glue_task(FLAGS.glue_task)\n",
    "\n",
    "    # Evaluate the weaved model\n",
    "    results = evaluation.evaluate_model(weaved_model, ds, metric)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(80 * \"*\")\n",
    "    print(\" Weaved Model Evaluation\")\n",
    "    print(80 * \"*\")\n",
    "    print(f\"{FLAGS.glue_task} {FLAGS.split} {FLAGS.n_examples} Examples\")\n",
    "    print(80 * \"-\")\n",
    "    print(f\"Metric: {FLAGS.favor_target_model}\")\n",
    "    print(f\"{metric.name}: {results[FLAGS.favor_target_model]}\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    app.run(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
